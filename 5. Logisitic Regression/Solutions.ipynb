{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. What does Oddsratio>1 imply?__\n",
    "\n",
    "    When predictor i.e X1 is binary -Relative probability of event to non-eventis higher when X1 is present vis-a-vis when X1 is absent\n",
    "    When X1 is continuous- Relative probabilityof event to non-event is higher when X1 increases by 1 unit\n",
    "\n",
    "__2. What is complete separation and quasi complete separation problem in Logistic regression?__\n",
    "    \n",
    "    Complete separation implies that there is some linear combination of the predictors that perfectly predicts the dependent variable. Whenever x > 3.5, y = 1 Whenever x < 3.5, y = 0 It is a case of complete separation\n",
    "    Quasi-complete separation problem exists whenever thereis complete separation except for atleast a single value of the predictor for which both values of the dependent variable occur. \n",
    "      For x > 4, y = 1 Forx < 4, y = 0 For x = 4, there exists one record with y = 0 and another with y =1 Itis a case of quasi-complete separation\n",
    "\n",
    "__3. Why can't we use the same cost function of MSE in case of logistic regression as we did in case of linear regression?__\n",
    "     \n",
    "     It’s because our prediction function is non-linear (due to sigmoid transform). Squaring this prediction as we do in MSE results in a non-convex function with many local minimums. If our cost function has many local minimums, gradient descent may not find the optimal global minimum.\n",
    "\n",
    "__4. What is the role of VIF(Variable inflation factor) in logistic regression variable selection process?__\n",
    "\n",
    "    VIF is used for tackling multicolinearity problem while variable or feature selection during logistic regression. We normally eliminate variables with VIF more than 2 and calculate the VIF for rest of the parameters again keeping them in model. This process continues till VIF of all the remaining variables are below 2\n",
    "\n",
    "__5. In what situation Oversampling is used in modelling process?__\n",
    "    \n",
    "    When event rate is low, the oversampling of events  Reduces the class biasness between events and non-events Improves model performance. Two common approaches of oversampling is \n",
    "    1. No change in non-events but increase the number of events by randomly replicating the existing  number of events\n",
    "    2. No change in events but downsize the number of non-events by random sampling of non-events\n",
    "\n",
    "__6. What are the disadvantages for Logistic regression?__\n",
    "    \n",
    "    1. Logistic Regression is also not one of the most powerful algorithms out there and can be easily outperformed by more complex ones. Also, we can’t solve non-linear problems with logistic regression since it’s decision surface is linear.\n",
    "    2. Logistic regression will not perform well with independent variables that are not correlated to the target variable and are very similar or correlated to each other\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
